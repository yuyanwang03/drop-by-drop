{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.060\n",
      "Test Score: -0.064\n",
      "Predicted daily water consumptions for June 2024: [np.float64(21982.422721576673), np.float64(20612.876341380845), np.float64(21502.153092352095), np.float64(21464.547047258304), np.float64(20553.21049469975), np.float64(21245.88306673882), np.float64(21715.182976551227), np.float64(21628.46994949495), np.float64(21333.429413059166), np.float64(21374.489749278506), np.float64(21285.73395165946), np.float64(20665.982636641143), np.float64(21606.282440392937), np.float64(21397.87407495283), np.float64(21579.20903571429), np.float64(20714.276208791212), np.float64(20198.473003968258), np.float64(20475.33988014763), np.float64(20853.09783216783), np.float64(22063.897704184703), np.float64(20337.56975649351), np.float64(21052.109169108666), np.float64(21660.970275613283), np.float64(20839.432923076925), np.float64(20501.62074847375), np.float64(20525.518014707515), np.float64(20150.979485930744), np.float64(20419.710732961492), np.float64(20697.34664313465), np.float64(20714.65933361084)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the raw data into features (X) and target (y).\n",
    "    \"\"\"\n",
    "    # Convert Date to Year, Month, Day\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "\n",
    "    # Add a column for the total number of tourists\n",
    "    df['Tourist Count'] = df['Tourist Accommodations'] + df['Hotel Overnight Stays']\n",
    "    \n",
    "    # Aggregate by removing 'Use' and summing values\n",
    "    df_agg = df.groupby(['Year', 'Month', 'Day', 'Census Section']).agg({\n",
    "        'Max Temperature': 'max',  # Maximum of Max Temperature\n",
    "        'Min Temperature': 'min',  # Minimum of Min Temperature\n",
    "        'Precipitation': 'sum',   # Total precipitation\n",
    "        'Tourist Count': 'sum',   # Total tourists\n",
    "        'Accumulated Consumption': 'sum'  # Total accumulated consumption\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Select relevant features\n",
    "    features = ['Year', 'Month', 'Day', 'Max Temperature', 'Min Temperature', \n",
    "                'Precipitation', 'Census Section', 'Tourist Count']\n",
    "    target = 'Accumulated Consumption'\n",
    "    \n",
    "    X = df_agg[features]\n",
    "    y = df_agg[target]\n",
    "    \n",
    "    return X, y, df_agg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(X, y):\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"Training Score: {model.score(X_train, y_train):.3f}\")\n",
    "    print(f\"Test Score: {model.score(X_test, y_test):.3f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_daily_consumptions(model, year, month, daily_data):\n",
    "    \"\"\"\n",
    "    Predict daily water consumption for the given month using the provided daily data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained machine learning model.\n",
    "        year: Year for prediction.\n",
    "        month: Month for prediction.\n",
    "        daily_data: DataFrame containing daily feature values for the month. It must include:\n",
    "            - Year, Month, Day\n",
    "            - Max Temperature, Min Temperature\n",
    "            - Precipitation\n",
    "            - Census Section\n",
    "            - Tourist Count\n",
    "    \n",
    "    Returns:\n",
    "        List of daily water consumptions for the given month.\n",
    "    \"\"\"\n",
    "    # Filter the data for the specific year and month\n",
    "    prediction_data = daily_data[(daily_data['Year'] == year) & (daily_data['Month'] == month)]\n",
    "    \n",
    "    # Ensure required columns are present\n",
    "    required_columns = ['Year', 'Month', 'Day', 'Max Temperature', 'Min Temperature',\n",
    "                        'Precipitation', 'Census Section', 'Tourist Count']\n",
    "    \n",
    "    if not all(col in prediction_data.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns in input data. Expected: {required_columns}\")\n",
    "    \n",
    "    # Predict daily consumption\n",
    "    daily_predictions = model.predict(prediction_data[required_columns])\n",
    "    \n",
    "    # Return daily predictions as a list\n",
    "    return list(daily_predictions)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your dataset\n",
    "    data_file = \"../data/local_data/merged_cleaned_data_NEW.csv\"  # Replace with your file path\n",
    "    df = pd.read_csv(data_file)\n",
    "    \n",
    "    # Preprocess the data\n",
    "    X, y, df_processed = preprocess_data(df)\n",
    "    \n",
    "    # Train the model\n",
    "    model = train_model(X, y)\n",
    "    \n",
    "    # Save the model for later use\n",
    "    with open(\"water_consumption_model.pkl\", \"wb\") as model_file:\n",
    "        pickle.dump(model, model_file)\n",
    "    \n",
    "    # Generate synthetic daily data for June 2024\n",
    "    daily_data = pd.DataFrame({\n",
    "        'Year': [2024] * 30,\n",
    "        'Month': [6] * 30,\n",
    "        'Day': list(range(1, 31)),\n",
    "        'Max Temperature': np.random.uniform(24, 26, 30),  # Example temperatures based on given data\n",
    "        'Min Temperature': np.random.uniform(16, 19, 30),\n",
    "        'Precipitation': np.random.uniform(0, 1.5, 30),  # Example precipitation values\n",
    "        'Census Section': [801901001] * 30,  # Example Census Section\n",
    "        'Tourist Accommodations': np.random.uniform(11000, 18000, 30),  # Adjusted range\n",
    "        'Hotel Overnight Stays': np.random.uniform(15000, 19000, 30),   # Adjusted range\n",
    "    })\n",
    "\n",
    "    # Add Tourist Count as the sum of Tourist Accommodations and Hotel Overnight Stays\n",
    "    daily_data['Tourist Count'] = daily_data['Tourist Accommodations'] + daily_data['Hotel Overnight Stays']\n",
    "\n",
    "\n",
    "    # Predict daily consumptions\n",
    "    daily_consumptions = predict_daily_consumptions(model, year=2024, month=6, daily_data=daily_data)\n",
    "    print(f\"Predicted daily water consumptions for June 2024: {daily_consumptions}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chronological Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.007\n",
      "Mean Absolute Error (MAE): 23672.23\n",
      "Mean Squared Error (MSE): 19569408340.50\n",
      "   Actual     Predicted\n",
      "0   30786  22754.874631\n",
      "1   13887  14762.285120\n",
      "2   15372  14762.285120\n",
      "3    3162   7845.744835\n",
      "4    1295   7845.744835\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the raw data into features (X) and target (y).\n",
    "    \"\"\"\n",
    "    # Convert Date to Year, Month, Day\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "\n",
    "    # Add a column for the total number of tourists\n",
    "    df['Tourist Count'] = df['Tourist Accommodations'] + df['Hotel Overnight Stays']\n",
    "    \n",
    "    # Select relevant features\n",
    "    features = ['Year', 'Month', 'Day', 'Max Temperature', 'Min Temperature', \n",
    "                'Precipitation', 'Census Section', 'Tourist Count']\n",
    "    target = 'Accumulated Consumption'\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    return X, y, df\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train the RandomForest model on the training data.\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"Training Score: {model.score(X_train, y_train):.3f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def split_chronologically(df, months_to_test=6):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and testing sets chronologically.\n",
    "    \n",
    "    Args:\n",
    "        df: Processed DataFrame with a 'Date' column.\n",
    "        months_to_test: Number of months to reserve for testing.\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test: Chronologically split features and target.\n",
    "    \"\"\"\n",
    "    # Sort the data by date\n",
    "    df = df.sort_values(by='Date')\n",
    "\n",
    "    # Identify the cutoff for the last `months_to_test`\n",
    "    last_date = df['Date'].max()\n",
    "    cutoff_date = last_date - pd.DateOffset(months=months_to_test)\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    train_data = df[df['Date'] <= cutoff_date]\n",
    "    test_data = df[df['Date'] > cutoff_date]\n",
    "\n",
    "    # Features and target\n",
    "    features = ['Year', 'Month', 'Day', 'Max Temperature', 'Min Temperature',\n",
    "                'Precipitation', 'Census Section', 'Tourist Count']\n",
    "    target = 'Accumulated Consumption'\n",
    "\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data[target]\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data[target]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def calculate_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the loss (e.g., Mean Absolute Error, Mean Squared Error).\n",
    "    \"\"\"\n",
    "    mae = np.mean(np.abs(y_true - y_pred))  # Mean Absolute Error\n",
    "    mse = np.mean((y_true - y_pred) ** 2)  # Mean Squared Error\n",
    "    return mae, mse\n",
    "\n",
    "\n",
    "def predict_daily_consumptions(model, X_test):\n",
    "    \"\"\"\n",
    "    Predict daily water consumption for the last 6 months using the actual test data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained machine learning model.\n",
    "        X_test: Feature DataFrame for the last 6 months.\n",
    "    \n",
    "    Returns:\n",
    "        List of daily water consumptions for the last 6 months.\n",
    "    \"\"\"\n",
    "    # Predict daily consumption\n",
    "    daily_predictions = model.predict(X_test)\n",
    "    \n",
    "    # Return daily predictions as a list\n",
    "    return list(daily_predictions)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your dataset\n",
    "    data_file = \"../data/local_data/merged_cleaned_data_NEW.csv\"  # Replace with your file path\n",
    "    df = pd.read_csv(data_file)\n",
    "    \n",
    "    # Preprocess the data\n",
    "    X, y, df_processed = preprocess_data(df)\n",
    "\n",
    "    # Add the Date column back for chronological splitting\n",
    "    df_processed['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Split the data chronologically (last 6 months as test set)\n",
    "    X_train, X_test, y_train, y_test = split_chronologically(df_processed, months_to_test=6)\n",
    "\n",
    "    # Train the model\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set (last 6 months)\n",
    "    y_pred = predict_daily_consumptions(model, X_test)\n",
    "\n",
    "    # Calculate the loss\n",
    "    mae, mse = calculate_loss(y_test.values, y_pred)\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    \n",
    "    # Save the model for later use\n",
    "    with open(\"water_consumption_model.pkl\", \"wb\") as model_file:\n",
    "        pickle.dump(model, model_file)\n",
    "\n",
    "    # Optional: You could compare the predictions with the actual values for daily consumption\n",
    "    comparison = pd.DataFrame({\n",
    "        'Actual': y_test.values,\n",
    "        'Predicted': y_pred\n",
    "    })\n",
    "    print(comparison.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Just by Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define Functions\n",
    "def preprocess_data(df):\n",
    "    # Convert Date to Year, Month, Day\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "    \n",
    "    # Select relevant features\n",
    "    features = ['Year', 'Month', 'Day', 'Max Temperature', 'Min Temperature']\n",
    "    target = 'Accumulated Consumption'\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def train_model(X, y):\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"Training Score: {model.score(X_train, y_train):.3f}\")\n",
    "    print(f\"Test Score: {model.score(X_test, y_test):.3f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_monthly_consumption(model, year, month, temperature_data):\n",
    "    \"\"\"\n",
    "    Predict daily water consumption for a given year, month, and temperature data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained machine learning model.\n",
    "        year: Year for prediction.\n",
    "        month: Month for prediction.\n",
    "        temperature_data: A dictionary with keys:\n",
    "            - 'Max Temperature': List of max daily temperatures for the month\n",
    "            - 'Min Temperature': List of min daily temperatures for the month\n",
    "    \n",
    "    Returns:\n",
    "        List of daily predicted water consumption.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame for the month\n",
    "    days_in_month = pd.date_range(start=f\"{year}-{month:02d}-01\", \n",
    "                                  end=f\"{year}-{month:02d}-{pd.Period(year=year, month=month, freq='M').days_in_month}\")\n",
    "    prediction_data = pd.DataFrame({\n",
    "        'Year': [year] * len(days_in_month),\n",
    "        'Month': [month] * len(days_in_month),\n",
    "        'Day': [d.day for d in days_in_month],\n",
    "        'Max Temperature': temperature_data['Max Temperature'],\n",
    "        'Min Temperature': temperature_data['Min Temperature'],\n",
    "    })\n",
    "    \n",
    "    # Predict daily consumption\n",
    "    predictions = model.predict(prediction_data)\n",
    "    return predictions\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your dataset\n",
    "    data_file = \"../data/local_data/merged_cleaned_data_NEW.csv\"  # Replace with your file pa  th\n",
    "    df = pd.read_csv(data_file)\n",
    "    \n",
    "    # Preprocess the data\n",
    "    X, y = preprocess_data(df)\n",
    "    \n",
    "    # Train the model\n",
    "    model = train_model(X, y)\n",
    "    \n",
    "    # Save the model for later use\n",
    "    with open(\"water_consumption_model.pkl\", \"wb\") as model_file:\n",
    "        pickle.dump(model, model_file)\n",
    "    \n",
    "    # Example prediction for June 2024\n",
    "    year = 2024\n",
    "    month = 6\n",
    "    temperature_data = {\n",
    "        'Max Temperature': [30, 31, 32, 33, 34, 35, 36, 36, 37, 38, 39, 40, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24],\n",
    "        'Min Temperature': [20, 21, 22, 23, 24, 25, 26, 26, 27, 28, 29, 30, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14],\n",
    "    }\n",
    "    \n",
    "    # Predict daily consumption\n",
    "    predictions = predict_monthly_consumption(model, year, month, temperature_data)\n",
    "    print(f\"Predicted daily water consumption for {year}-{month:02d}:\")\n",
    "    print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
